// Copyright (c) 2019 - 2022 RacoonStudios

//[-------------------------------------------------------]
//[ Definitions                                           ]
//[-------------------------------------------------------]
@includepiece(../Shared/SP_Core.asset)
	@insertpiece(SetCrossPlatformSettings)


//[-------------------------------------------------------]
//[ Input / output                                        ]
//[-------------------------------------------------------]
// Attribute input / output
INPUT_BEGIN_VERTEX
	INPUT_VERTEX_POSITION(0, float3, Position)	// Object space vertex position
	INPUT_VERTEX_DRAW_ID(1)						// Draw ID
INPUT_END_VERTEX
OUTPUT_BEGIN_VERTEX
	NOINTERPOLATION_INTERPOLATION_MODIFIER OUTPUT_TEXTURE_COORDINATE(1, float4, CameraVolumeSpacePosition,				  0)	// Volume space camera position, w-component = The assigned material slot inside the material uniform buffer
										   OUTPUT_TEXTURE_COORDINATE(2, float4, VolumeSpacePositionVS,					  1)	// Volume space ray end position, w-component = Uniform world space to object space scale, only uniform scale is supported to keep things simple
	NOINTERPOLATION_INTERPOLATION_MODIFIER OUTPUT_TEXTURE_COORDINATE(3, float4, ViewSpaceToObjectSpaceRotationQuaternion, 2)	// View space to object space rotation quaternion
										   OUTPUT_POSITION			(0)															// Clip space vertex position as output, left/bottom is (-1,-1) and right/top is (1,1)
OUTPUT_END_VERTEX

// Uniform buffers
struct PassDataStruct
{
	float4x4 WorldSpaceToClipSpaceMatrix[2];
	float4   ViewSpaceToWorldSpaceQuaternion[2];
	float3	 WorldSpaceCameraPosition[2];
	float2   InverseViewportSize;
	float2	 ProjectionParameters;
	float	 JitterFactor;
};
UNIFORM_BUFFER_BEGIN(0, 0, PassUniformBuffer, 0)
	PassDataStruct PassData;
UNIFORM_BUFFER_END
UNIFORM_BUFFER_BEGIN(2, 0, InstanceUniformBuffer, 2)
	// x = The instance texture buffer start index
	// y = The assigned material slot inside the material uniform buffer
	// z = The custom parameters start index inside the instance texture buffer
	// w = Unused
	uint4 InstanceIndicesArray[FAST_SHADER_BUILD_HACK(4096)];	// 64 KiB
UNIFORM_BUFFER_END

// Texture buffers
// -> We're using base shader register 3 instead of 0 to be compatible to the OpenGL ES 3 RHI implementation texture buffer emulation, which is using an uniform buffer for the emulation
TEXTURE_BUFFER(2, 1, float4, InstanceTextureBuffer, 3)	// "POSITION_ROTATION_SCALE"


//[-------------------------------------------------------]
//[ Functions                                             ]
//[-------------------------------------------------------]
@includepiece(../Shared/SP_Normal.asset)
	@insertpiece(DefineGetTangentFrame)


//[-------------------------------------------------------]
//[ Main                                                  ]
//[-------------------------------------------------------]
MAIN_BEGIN_VERTEX
	// Get object space to world space data
	uint4  instanceIndices	  = InstanceIndicesArray[MAIN_INPUT_DRAW_ID_VERTEX];
	float3 position			  = TEXTURE_BUFFER_FETCH(InstanceTextureBuffer, instanceIndices.x).xyz;
	float4 rotationQuaternion = TEXTURE_BUFFER_FETCH(InstanceTextureBuffer, instanceIndices.x + 1u);
	float3 scale			  = TEXTURE_BUFFER_FETCH(InstanceTextureBuffer, instanceIndices.x + 2u).xyz;

	// Get the object space position which is centered around the null point with (-0.5 ... 0.5)
	float3 objectSpacePosition = MAIN_INPUT(Position);

	// Calculate the world space vertex position
	float3 worldSpacePosition = MultiplyQuaternionVector(rotationQuaternion, objectSpacePosition * scale) + position;

	// Calculate the clip space vertex position, left/bottom is (-1,-1) and right/top is (1,1)
	MAIN_OUTPUT_POSITION = MATRIX_MUL(PassData.WorldSpaceToClipSpaceMatrix[MAIN_INPUT_STEREO_EYE_INDEX], float4(worldSpacePosition, 1.0f));

	// Get volume space camera position by first transforming the available camera world space position into a camera object space position and then transforming it into a camera volume space position via +0.5
	// -> Using the conjugated quaternion as inverse since we're using a rotation quaternion (which is normalized by definition)
	// -> w-component = Pass through the assigned material slot inside the material uniform buffer
	float4 worldSpaceToObjectSpaceRotationQuaternion = float4(-rotationQuaternion.x, -rotationQuaternion.y, -rotationQuaternion.z, rotationQuaternion.w);
	@property(SinglePassStereoInstancing)
		position = PassData.WorldSpaceCameraPosition[MAIN_INPUT_STEREO_EYE_INDEX] - position;
	@else
		// Possible optimization when not using stereo rendering: Since we're using camera relative rendering, "PassData.WorldSpaceCameraPosition - position" becomes just "-position"
		position = -position;
	@end
	MAIN_OUTPUT(CameraVolumeSpacePosition) = float4(MultiplyQuaternionVector(worldSpaceToObjectSpaceRotationQuaternion, position) * (1.0f / scale) + 0.5f, CAST_TO(instanceIndices.y, float));

	// Object space position to volume space position and rotation quaternion
	MAIN_OUTPUT(VolumeSpacePositionVS) = float4(objectSpacePosition + 0.5f, 1.0f / scale.x);	// w-component = Uniform world space to object space scale, only uniform scale is supported to keep things simple
	MAIN_OUTPUT(ViewSpaceToObjectSpaceRotationQuaternion) = MultiplyQuaternions(worldSpaceToObjectSpaceRotationQuaternion, PassData.ViewSpaceToWorldSpaceQuaternion[MAIN_INPUT_STEREO_EYE_INDEX]);
MAIN_END_VERTEX(MAIN_OUTPUT_POSITION)
